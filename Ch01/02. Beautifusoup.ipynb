{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Beautifulsoup로 스크레이핑하기\n",
    "\n",
    "스크레이핑이란 웹 사이트에서 데이터를 추출하고, 원하는 정보를 추출하는 것임. 최근에는 인터넷에 데이터가 너무 많으므로 스크레이핑을 잘 활용하는 것이 중요함.\n",
    "\n",
    "파이썬으로 스크레이핑할 때 뺴놓을 수 없는 라이브러리가 바로 \"BeautifulSoup\"임. 이 라이브러리를 이용하면 간단하게 HTML과 XML에서 정보를 추출할 수 있음.\n",
    "\n",
    "최근 스크레이핑 라이브러리는 다운로드부터 HTML 분석까지 모두 해주는 경우가 많은데, BeautifulSoup는 어디까지나 HTML과 XML을 분석해주는 라이브러리임. BeautifulSoup 자체에는 다운로드 기능이 없으므로 주의해줘야함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BeautifulSoup 설치하기\n",
    "\n",
    "파이썬 라이브러리를 설치할 때는 pip 명령어를 사용함. pip란 파이썬 패키지 관리 시스템임.\n",
    "\n",
    "파이썬 패키지는 Python Package Index(PyPI)에서 확인할 수 있음. pip을 이용하면 PyPi에 있는 패키지를 명령어 한 줄로 설치할 수 있음.\n",
    "\n",
    "pip로 BeautifulSoup를 설치할 때는 다음과 같은 명령어를 실행함\n",
    " \n",
    " $ pip3 install beautifulsoup4\n",
    " \n",
    " 참고로 pip3는 pip의 파이썬3 버전임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BeautifulSoup 기본 사용법\n",
    "\n",
    "일단은 Beautifulsoup의 기본적인 사용법을 확인해봅시다. 다음 프로그램은 BeautifulSoup를 이용해 분석하는 간단한 예제임. 웹 사이트로부터 HTML을 가져와서 사용하는 것이 아니라 HTML을 문자열로 만들어 사용하고 있음. 그리고 문자열 분석을 완료하면 결과를 출력함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1 =  스크레이핑란? \n",
      "p =  웹 페이지를 분석하는 것\n",
      "p =  원하는 부분을 추출하는 것\n"
     ]
    }
   ],
   "source": [
    "# 라이브러리 읽어 들이기 -- 1\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 분석하고 싶은 HTML -- 2\n",
    "html = \"\"\"\n",
    "<html><body>\n",
    "    <h1> 스크레이핑란? </h1>\n",
    "    <p> 웹 페이지를 분석하는 것</p>\n",
    "    <p> 원하는 부분을 추출하는 것</p>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "\n",
    "# HTML 분석하기 -- 3\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# 원하는 부분 추출하기 -- 4\n",
    "h1 = soup.html.body.h1\n",
    "p1 = soup.html.body.p\n",
    "p2 = p1.next_sibling.next_sibling\n",
    "\n",
    "# 요소의 글자를 출력하기 -- 5\n",
    "print(\"h1 = \" + h1.string)\n",
    "print(\"p = \" + p1.string)\n",
    "print(\"p = \" + p2.string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "프로그램 (1)에서는 Beautifulsoup 라이브러리를 읽어 들임. (2)에서는 분석 대상 HTML을 지정함.\n",
    "프로그램의 (3)에서는 BeautifulSoup 인스턴스를 생성. 이때 첫 번째 매개변수에 HTML을 지정함. 그리고 두 번째 매개변수에는 분석할 분석기(parser)의 종류를 지정함. HTML을 분석할 때는 \"html.parser\"라고 지정함.\n",
    "\n",
    "프로그램의 (4)에서 원하는 부분을 추출함. 정상적으로 분석됐다면 HTML의 구조처럼 루트 요소인 <html>에서 마침표(.)를 사용해 값에 접근할 수 있음. 코드에서는 \"soup.html.body.h1\" 이라고 적었는데, HTML, body, h1 에 있는 요소에 접근한 것임. 프로그램의 (5)에서는 string 속성에 접근해서 요소의 글자 부분을 추출함.\n",
    "    \n",
    "분석할 때 HTML 내부에는 <p> 태그가 2개 있는데 soup.html.body.p라고 접근하면 앞쪽에 있는 <p> 태그를 추출하게 됨. 이때 첫 번째의 next_sibling에서는 </p> 뒤에 있는 줄바꿈 또는 공백이 추출됨. 따라서 next_sibling을 한 번 더 사용해 2번째 <p> 태그를 추출함.\n",
    "    \n",
    "HTML의 구조를 알고 있다면 쉽게 원하는 요소를 추출할 수 있음. 하지만 루투부터 \"html.body..\" 형태로 HTML 구조를 하나하나 적어 나가는 것은 조금 귀찮고 복잡함. 따라서 이어서 간단하게 요소를 찾아내는 방법을 소개하겠음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# id로 요소를 찾는 방법\n",
    "\n",
    "BeautifulSoup는 루트부터 하나하나 요소를 찾는 방법 말고도 id속성을 지정해서 요소를 찾는 find()메서드라는 메서드를 제공함. 그럼 곧바로 코드를 살펴보겠음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#title = 스크래핑이란? \n",
      "#body = 원하는 부분을 추출하는 것 \n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"\n",
    "<html>\n",
    "    <body>\n",
    "        <h1 id= \"title\"> 스크래핑이란? </h>\n",
    "        <p> 웹 페이지를 분석하는 것 </p>\n",
    "        <p id = \"body\"> 원하는 부분을 추출하는 것 </p>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# HTML 분석하기 -- 1\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# find() 메서드로 원하는 부분 추출하기 -- 2\n",
    "title = soup.find(id = \"title\")\n",
    "body  = soup.find(id = \"body\")\n",
    "\n",
    "# 텍스트 부분 출력하기\n",
    "print(\"#title =\" + title.string)\n",
    "print(\"#body =\" + body.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "프로그램의 (1)에서는 BeautifulSoup 인스턴스를 생성함. 첫 번째 매개변수에 분석하고 싶은 HTML을 지정함.\n",
    "(2)에서는 id를 지정해 요소를 추출함. find() 메서드에 \"id=<값>\" 형태로 매개변수를 지정해 요소를 검색함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 여러 개의 요소 추출하기 -  find_all() 메서드\n",
    "\n",
    "참고로 여로 개의 태그를 한 번에 추출하고 싶을 때는 find_all() 메서드를 사용함. 다음 코드는 HTML 내부에 있는 여러 개의 \"a\" 태그를 추출하는 프로그램임. \"a\" 태그는 하이퍼링크 태그이므로, 링크 대상은 href 속성으로 지정하고 링크를 설명하는 텍스트는 태그 내부에 입력. 다음 코드는 설명 글자와 링크 대상 URL을 추출하고 출력하는 예임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " naver  > http://www.naver.com\n",
      " daum  > http://www.daum.net\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"\n",
    "<html>\n",
    "    <body>\n",
    "        <ul>\n",
    "            <li><a href = \"http://www.naver.com\"> naver </a></li>\n",
    "            <li><a href = \"http://www.daum.net\"> daum </a></li>\n",
    "        </ul>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# HTML 분석하기 -- 1\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# find_all() 메서드로 추출하기 -- 2\n",
    "links = soup.find_all(\"a\")\n",
    "\n",
    "# 링크 목록 출력하기 -- 3\n",
    "for a in links:\n",
    "    href = a.attrs['href']\n",
    "    text = a.string\n",
    "    print(text, \">\", href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
